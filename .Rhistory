prediction <- predict(rf_fit, new_data, type="prob")
prediction_percentage <- (prediction[1,2])*100
# Display using renderUI to have more control over appearance
output$prediction <- renderUI({
tagList(
h3("Probabilidad de Encontrar Una Infracción:"),
tags$div(
class = "progress",
tags$div(
class = "progress-bar",
role = "progressbar",
style = sprintf("width: %s%%;", prediction_percentage),
sprintf("%s%%", round(prediction_percentage))
)
)
)
})
})
}
shinyApp(ui = ui, server = server)
pacman::p_load(
janitor,
tidymodels,
tidyverse,
StanHeaders
)
raw_data <- read.csv("~/Binomial_dataset2.csv")    %>% # Modify here to read from correct folder
clean_names()
# Trim observations and build a factor version for classification
raw_data$tiempo = raw_data$tiempo/60
illegal <- raw_data %>%
drop_na() %>%                                                                 # Remove all observations with NA
filter(!agente == "Sin_Actividad") %>%                                        # Remove agente sin actividad
mutate(f_respuesta = as.factor(ifelse(respuesta == 1, "Si", "No")),           # Recode 0 and 1 to a factor
ano = as.factor(ano))                                                  # Recode year as factor
# Build training (70%) and testing (30%) data sets
set.seed(1)                                                                     # Random seed
illegal_split <- initial_split(data = illegal,
prop = 0.50,                                     # Proportion dstined for training
strata = especierod)                             # Stratified sampling to make sure we get 70% of each species. Just as good practice
illegal_train <- training(illegal_split)                                        # Extract the training set
illegal_test  <-  testing(illegal_split)                                        # Extract the testing set
## BUILD ML PIPELINE -----------------------------------------------------------
# Define the "recipe", made up of the formulation and data transformations
illegal_rec <-
recipe(
# Formula relating the (factor)response to relevant variables used in the hierarchical bayesian model
formula = f_respuesta ~ tiempo + n_fiscalizadores_por_cometido + medida + agente + especierod + region +  acciones_por_cometido  + oficina + mes,
data = illegal_train) %>%
# Add a step to transfomr "tiempo" and "n_fiscalizadores_por_cometido" to be between 0 and 1
#step_range(min = 0,
#          max = 1,
#         ranges = c("tiempo", "n_fiscalizadores_por_cometido")) #%>%
# Add a step to allow for species to change in the future (e.g. if the prediction is made for a species not included here)
step_novel(especierod)
# Define the model specification
rf_model <- rand_forest(trees = 1000, min_n = 5, mtry = NULL) %>%
set_engine("ranger", class.weights = c(Si = 0.9, No = 0.1)) %>%
set_mode("classification")
workflow <-
workflow() %>%
add_model(rf_model) %>%                                                       # Adds the model as defined
add_recipe(illegal_rec)                                                       # Adds the recipe we defined
# Fit the model ----------------------------------------------------------------
rf_fit <- fit(
object = workflow,                                                            # What to fit?
data = illegal_train                                                          # What to fit it to
)
# See model output
rf_fit
library(shiny)
library(dplyr)
ui <- fluidPage(
titlePanel("App Predicción Infracciones"),
sidebarLayout(
sidebarPanel(
selectInput("region", "Region:", choices = unique(illegal$region)),
selectInput("oficina", "Oficina:", choices = ""),
selectInput("especierod", "Especie:", choices = ""),
selectInput("medida", "Medida:", choices = ""),
selectInput("agente", "Agente:", choices = ""),
sliderInput("tiempo", "Duración del Cometido (horas):", min = 1, max = 24, value = 1),
sliderInput("n_fiscalizadores_por_cometido", "Número Fiscalizadores en el Cometido:", min = 1, max = 10, value = 1),
sliderInput("acciones_por_cometido", "Acciones Por Cometido:", min = 1, max = 20, value = 1),
sliderInput("mes", "Mes del Año (por ejemplo Enero=1):", min = 1, max = 12, value = 1),
actionButton("predict", "Predecir")
),
mainPanel(
uiOutput("prediction")
)
)
)
server <- function(input, output, session) {
# Update office choices based on selected region
observe({
filtered_offices <- illegal %>%
filter(region == input$region) %>%
distinct(oficina) %>%
pull(oficina)
updateSelectInput(session, "oficina", choices = filtered_offices)
})
# Update species choices based on selected office
observe({
filtered_species <- illegal %>%
filter(oficina == input$oficina) %>%
distinct(especierod) %>%
pull(especierod)
updateSelectInput(session, "especierod", choices = filtered_species)
})
# Update medida choices based on selected species
observe({
filtered_medida <- illegal %>%
filter(especierod == input$especierod) %>%
distinct(medida) %>%
pull(medida)
updateSelectInput(session, "medida", choices = filtered_medida)
})
# Update agente choices based on selected medida
observe({
filtered_agente <- illegal %>%
filter(medida == input$medida) %>%
distinct(agente) %>%
pull(agente)
updateSelectInput(session, "agente", choices = filtered_agente)
})
observeEvent(input$predict, {
new_data <- tibble(
tiempo = input$tiempo,
n_fiscalizadores_por_cometido = input$n_fiscalizadores_por_cometido,
medida = input$medida,
agente = input$agente,
especierod = input$especierod,
region = input$region,
acciones_por_cometido = input$acciones_por_cometido,
oficina = input$oficina,
mes = input$mes
)
prediction <- predict(rf_fit, new_data, type="prob")
prediction_percentage <- (prediction[1,2])*100
# Display using renderUI to have more control over appearance
output$prediction <- renderUI({
tagList(
h3("Probabilidad de Encontrar Una Infracción:"),
tags$div(
class = "progress",
tags$div(
class = "progress-bar",
role = "progressbar",
style = sprintf("width: %s%%;", prediction_percentage),
sprintf("%s%%", round(prediction_percentage))
)
)
)
})
})
}
shinyApp(ui = ui, server = server)
library(shiny)
library(dplyr)
ui <- fluidPage(
titlePanel("App Predicción Infracciones"),
sidebarLayout(
sidebarPanel(
selectInput("region", "Region:", choices = unique(illegal$region)),
selectInput("oficina", "Oficina:", choices = ""),
selectInput("especierod", "Especie:", choices = ""),
selectInput("medida", "Medida:", choices = ""),
selectInput("agente", "Agente:", choices = ""),
sliderInput("tiempo", "Duración del Cometido (horas):", min = 1, max = 24, value = 1),
sliderInput("n_fiscalizadores_por_cometido", "Número Fiscalizadores en el Cometido:", min = 1, max = 10, value = 1),
sliderInput("acciones_por_cometido", "Acciones Por Cometido:", min = 1, max = 20, value = 1),
sliderInput("mes", "Mes del Año (por ejemplo Enero=1):", min = 1, max = 12, value = 1),
actionButton("predict", "Predecir")
),
mainPanel(
uiOutput("prediction")
)
)
)
server <- function(input, output, session) {
# Update office choices based on selected region
observe({
filtered_offices <- illegal %>%
filter(region == input$region) %>%
distinct(oficina) %>%
pull(oficina)
updateSelectInput(session, "oficina", choices = filtered_offices)
})
# Update species choices based on selected office
observe({
filtered_species <- illegal %>%
filter(oficina == input$oficina) %>%
distinct(especierod) %>%
pull(especierod)
updateSelectInput(session, "especierod", choices = filtered_species)
})
# Update medida choices based on selected species
observe({
filtered_medida <- illegal %>%
filter(especierod == input$especierod) %>%
distinct(medida) %>%
pull(medida)
updateSelectInput(session, "medida", choices = filtered_medida)
})
# Update agente choices based on selected medida
observe({
filtered_agente <- illegal %>%
filter(medida == input$medida) %>%
distinct(agente) %>%
pull(agente)
updateSelectInput(session, "agente", choices = filtered_agente)
})
observeEvent(input$predict, {
new_data <- tibble(
tiempo = input$tiempo,
n_fiscalizadores_por_cometido = input$n_fiscalizadores_por_cometido,
medida = input$medida,
agente = input$agente,
especierod = input$especierod,
region = input$region,
acciones_por_cometido = input$acciones_por_cometido,
oficina = input$oficina,
mes = input$mes
)
prediction <- predict(rf_fit, new_data, type="prob")
prediction_percentage <- (prediction[1,2])*100
# Display using renderUI to have more control over appearance
output$prediction <- renderUI({
tagList(
h3("Probabilidad de Encontrar Una Infracción:"),
tags$div(
class = "progress",
tags$div(
class = "progress-bar",
role = "progressbar",
style = sprintf("width: %s%%;", prediction_percentage),
sprintf("%s%%", round(prediction_percentage))
)
)
)
})
})
}
shinyApp(ui = ui, server = server)
raw_data <- read.csv("Binomial_dataset2.csv")    %>% # Modify here to read from correct folder
clean_names()
library(shiny)
library(dplyr)
ui <- fluidPage(
titlePanel("App Predicción Infracciones"),
sidebarLayout(
sidebarPanel(
selectInput("region", "Region:", choices = unique(illegal$region)),
selectInput("oficina", "Oficina:", choices = ""),
selectInput("especierod", "Especie:", choices = ""),
selectInput("medida", "Medida:", choices = ""),
selectInput("agente", "Agente:", choices = ""),
sliderInput("tiempo", "Duración del Cometido (horas):", min = 1, max = 24, value = 1),
sliderInput("n_fiscalizadores_por_cometido", "Número Fiscalizadores en el Cometido:", min = 1, max = 10, value = 1),
sliderInput("acciones_por_cometido", "Acciones Por Cometido:", min = 1, max = 20, value = 1),
sliderInput("mes", "Mes del Año (por ejemplo Enero=1):", min = 1, max = 12, value = 1),
actionButton("predict", "Predecir")
),
mainPanel(
uiOutput("prediction")
)
)
)
server <- function(input, output, session) {
# Update office choices based on selected region
observe({
filtered_offices <- illegal %>%
filter(region == input$region) %>%
distinct(oficina) %>%
pull(oficina)
updateSelectInput(session, "oficina", choices = filtered_offices)
})
# Update species choices based on selected office
observe({
filtered_species <- illegal %>%
filter(oficina == input$oficina) %>%
distinct(especierod) %>%
pull(especierod)
updateSelectInput(session, "especierod", choices = filtered_species)
})
# Update medida choices based on selected species
observe({
filtered_medida <- illegal %>%
filter(especierod == input$especierod) %>%
distinct(medida) %>%
pull(medida)
updateSelectInput(session, "medida", choices = filtered_medida)
})
# Update agente choices based on selected medida
observe({
filtered_agente <- illegal %>%
filter(medida == input$medida) %>%
distinct(agente) %>%
pull(agente)
updateSelectInput(session, "agente", choices = filtered_agente)
})
observeEvent(input$predict, {
new_data <- tibble(
tiempo = input$tiempo,
n_fiscalizadores_por_cometido = input$n_fiscalizadores_por_cometido,
medida = input$medida,
agente = input$agente,
especierod = input$especierod,
region = input$region,
acciones_por_cometido = input$acciones_por_cometido,
oficina = input$oficina,
mes = input$mes
)
prediction <- predict(rf_fit, new_data, type="prob")
prediction_percentage <- (prediction[1,2])*100
# Display using renderUI to have more control over appearance
output$prediction <- renderUI({
tagList(
h3("Probabilidad de Encontrar Una Infracción:"),
tags$div(
class = "progress",
tags$div(
class = "progress-bar",
role = "progressbar",
style = sprintf("width: %s%%;", prediction_percentage),
sprintf("%s%%", round(prediction_percentage))
)
)
)
})
})
}
shinyApp(ui = ui, server = server)
library(ranger)
`La+Pesca+Ilegal+.+2nd+Version_September+26%2C+2023_11.37` <- read.csv("~/Desktop/La+Pesca+Ilegal+-+2nd+Version_September+26%2C+2023_11.37.csv")
View(`La+Pesca+Ilegal+.+2nd+Version_September+26%2C+2023_11.37`)
library(shiny)
library(lubridate)
library(tidymodels)
library(shiny)
?observe
detach("package:infer", unload = TRUE)
chatgpt:::run_addin_ask_chatgpt()
#add open ai key
system("OPENAI_API_KEY=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", intern=TRUE)
#add open ai key
system("OPENAI_API_KEY=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", intern=TRUE)
#add open ai key
Sys.setenv(OPENAI_API_KEY = "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")
chatgpt:::run_addin_ask_chatgpt()
gptstudio:::chat_gpt_addin()
#plot the model
plot(rf_fit$fit)
pacman::p_load(
janitor,
tidymodels,
tidyverse,
StanHeaders,
ranger,
lubridate
)
setwd("~/Dropbox/Back up todo/Sernapesca Project/Models and Data/ML")
raw_data <- read.csv("Binomial_dataset2.csv")      %>% # Modify here to read from correct folder
clean_names()
setwd("~/Dropbox/Back up todo/Sernapesca Project/Models and Data/ML/SernapescaApp")
raw_data <- read.csv("Binomial_dataset2.csv")      %>% # Modify here to read from correct folder
clean_names()
# Trim observations and build a factor version for classification
raw_data$tiempo = raw_data$tiempo/60
illegal <- raw_data %>%
drop_na() %>%                                                                 # Remove all observations with NA
filter(!agente == "Sin_Actividad") %>%                                        # Remove agente sin actividad
mutate(f_respuesta = as.factor(ifelse(respuesta == 1, "Si", "No")),           # Recode 0 and 1 to a factor
ano = as.factor(ano))                                                  # Recode year as factor
##Get week
AA=parse_date_time(illegal$fecha, orders   = c('dmy HM', 'Ymd','dmY HM' , 'dmY HMS', 'Ymd HMS'))
BB = format(as.POSIXct(AA, format = '%d/%m/%Y %H:%M:%S'),format = '%Y/%m/%d')
illegal$semana<- week(BB)
##Get day of the week
illegal$dia <-wday(BB)
set.seed(1)                                                                     # Random seed
illegal_split <- initial_split(data = illegal,
prop = 0.7,                                     # Proportion dstined for training
strata = especie)                             # Stratified sampling to make sure we get 70% of each species. Just as good practice
illegal_train <- training(illegal_split)                                        # Extract the training set
illegal_test  <-  testing(illegal_split)                                        # Extract the testing set
## BUILD ML PIPELINE -----------------------------------------------------------
# Define the "recipe", made up of the formulation and data transformations
illegal_rec <-
recipe(
# Formula relating the (factor)response to relevant variables used in the hierarchical bayesian model
formula = f_respuesta ~ tiempo + n_fiscalizadores_por_cometido +  agente + especie + region  + oficina + semana + dia,
data = illegal_train) %>%
# Add a step to transfomr "tiempo" and "n_fiscalizadores_por_cometido" to be between 0 and 1
#step_range(min = 0,
#          max = 1,
#         ranges = c("tiempo", "n_fiscalizadores_por_cometido")) #%>%
# Add a step to allow for species to change in the future (e.g. if the prediction is made for a species not included here)
step_novel(especie)
# Define the model specification
rf_model <- rand_forest(trees =250, min_n = 5, mtry = NULL) %>%
set_engine("ranger", class.weights = c(Si = 0.9, No = 0.1)) %>%
set_mode("classification")
workflow <-
workflow() %>%
add_model(rf_model) %>%                                                       # Adds the model as defined
add_recipe(illegal_rec)                                                       # Adds the recipe we defined
# Fit the model ----------------------------------------------------------------
rf_fit <- fit(
object = workflow,                                                            # What to fit?
data = illegal_train                                                          # What to fit it to
)
#plot the model
plot(rf_fit$fit)
# Load necessary libraries
library(tune)
library(yardstick)
# Set the event level for the metric
event_level("binary", "first")
# Load necessary libraries
library(tune)
library(yardstick)
# Set the event level for the metric
event_level("binary", "first")
# Set the event level for the metric
yardstick :: event_level("binary", "first")
# Load necessary libraries
library(tune)
library(yardstick)
# Create a grid of hyperparameters to search over
rf_grid <- grid_regular(
trees(),
min_n(),
mtry(),
levels = c(10, 20, 30)  # You may want to choose different levels depending on your computational resources
)
# Create a parameter object for the mtry hyperparameter
mtry_param <- dials::mtry(range = c(1, sqrt(ncol(illegal_train) - 1)))
# Create a parameter object for the mtry hyperparameter
mtry_param <- dials::mtry(range = c(1, sqrt(ncol(illegal_train) - 1)))
library(dials)
# Create a parameter object for the mtry hyperparameter
mtry_param <- dials::mtry(range = c(1, floor(sqrt(ncol(illegal_train) - 1))))
# Create a grid of hyperparameters to search over
rf_grid <- grid_regular(
trees(),
min_n(),
mtry_param(),
levels = c(10, 20, 30)  # You may want to choose different levels depending on your computational resources
)
# Create a parameter object for the mtry hyperparameter
mtry_param <- dials::mtry(range = c(1, floor(sqrt(ncol(illegal_train) - 1))))
mtry_param
# Create a grid of hyperparameters to search over
rf_grid <- grid_regular(
trees(),
min_n(),
mtry_param(),
levels = c(10, 20, 30)  # You may want to choose different levels depending on your computational resources
)
# Create a grid of hyperparameters to search over
rf_grid <- grid_regular(
trees(),
min_n(),
mtry_param,
levels = c(10, 20, 30)  # You may want to choose different levels depending on your computational resources
)
# Define the resampling method - using 5-fold cross-validation here as an example
cv_folds <- vfold_cv(illegal_train, v = 5)
# Define a metric to optimize - F1 Score
metric <- metric_set(f_meas)
# Perform the grid search
rf_tune_results <- tune_grid(
object = workflow,  # Your existing workflow
resamples = cv_folds,  # Resampling method
grid = rf_grid,  # Grid of hyperparameters
metrics = metric  # Metrics to optimize
)
# Load necessary libraries
library(tune)
library(yardstick)
library(dials)
# Define the model specification with tune() placeholders for the parameters to be tuned
rf_model <- rand_forest(
trees = tune(),
min_n = tune(),
mtry = tune()
) %>%
set_engine("ranger", class.weights = c(Si = 0.9, No = 0.1)) %>%
set_mode("classification")
workflow <-
workflow() %>%
add_model(rf_model) %>%                                                       # Adds the model as defined
add_recipe(illegal_rec)                                                       # Adds the recipe we defined
# Create a grid of hyperparameters to search over
rf_grid <- grid_regular(
trees(range = c(100, 500)),
min_n(range = c(1, 10)),
mtry(range = c(1, floor(sqrt(ncol(illegal_train) - 1)))),
levels = c(10, 20, 30)
)
# Define the resampling method - using 5-fold cross-validation here as an example
cv_folds <- vfold_cv(illegal_train, v = 5)
# Define a metric to optimize - F1 Score
metric <- metric_set(f_meas)
# Perform the grid search
rf_tune_results <- tune_grid(
object = workflow,  # Your existing workflow
resamples = cv_folds,  # Resampling method
grid = rf_grid,  # Grid of hyperparameters
metrics = metric  # Metrics to optimize
)
